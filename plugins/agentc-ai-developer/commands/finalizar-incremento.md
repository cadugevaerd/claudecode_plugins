---
description: Finalize current increment with metrics validation, coverage check (â‰¥70%), regression tests, and automatic decision on next steps
allowed-tools: Read, Bash, Write, Grep, AskUserQuestion
argument-hint: ''
---

# Finalizar Incremento - Complete Increment Validation Loop

Finalize the current increment by validating metrics, ensuring test coverage â‰¥70%, checking for regressions, and automatically determining whether to continue or conclude the slice.

## Preconditions

Verify before starting:

1. **SLICE_N_TRACKER.md exists** - Slice must be initialized
1. **Section 3 (INCREMENTOS) exists** - Must have created incremento with `/novo-incremento`
1. **Incremento N exists with status "Em Progresso"** - Current increment active
1. **At least one commit since incremento start** - Code changes made
1. **Git working directory is clean** - No uncommitted changes
1. **pytest-cov installed** - For coverage validation: `pip install pytest-cov`
1. **CI.py exists in project root** - For metrics collection

If any precondition fails: Stop and guide user to complete prerequisites.

## Validation Pipeline

### Step 1: Verify Incremento State

1. **Locate current incremento**:

   - Find latest `### Incremento {N}:` in Section 3
   - Verify status: `- **Status**: â¡ï¸ Em Progresso`
   - Extract start time: `- **Iniciado em**: {ISO_TIMESTAMP}`

1. **Verify git commits**:

   - Get current branch: `git branch --show-current`
   - Count commits since incremento start
   - If 0 commits: Ask user "No changes made. Continue anyway? (y/n)"

1. **Verify uncommitted changes**:

   - Run: `git status --porcelain`
   - If any uncommitted: Block with "Commit your changes first: git add . && git commit"

### Step 2: Capture Final Metrics

Execute CI.py to capture final metrics:

1. **Run CI.py**:

   - Execute: `uv run CI.py` (or `python CI.py`)
   - Capture: success_rate, test_count, latency_ms, timestamp
   - If fails: Display error and ask to fix tests first

1. **Extract metrics**:

   ```
   Final Metrics:
   - Success Rate: {X}%
   - Test Count: {N} tests
   - Avg Latency: {Y}ms
   - Timestamp: {ISO_TIMESTAMP}
   ```

1. **Compare to baseline**:

   - Read Section 2: Baseline metrics
   - Calculate delta:
     - Success Rate Delta: (Final - Baseline)%
     - Test Count Delta: (Final - Baseline)
     - Latency Delta: (Final - Baseline)ms

### Step 3: Validate Test Coverage (BLOCKING)

Validate that test coverage >= 70%:

1. **Run pytest with coverage**:

   ```bash
   uv run pytest --cov --cov-report=json --cov-report=term
   ```

1. **Extract coverage %**:

   - Parse output: `TOTAL` coverage line
   - Extract percentage: {Z}%

1. **Validate >= 70%**:

   - If coverage >= 70%:
     - Continue to Step 4
   - If coverage < 70%:
     - **BLOCK**: "âŒ Coverage too low: {Z}% < 70% minimum"
     - Display: "Add more tests to reach 70% coverage"
     - Display: Missing coverage areas
     - Exit with error (do NOT continue)

### Step 4: Validate Regressions

Check for breaking changes:

1. **Get baseline test count**:

   - Read Section 2: `- **Test Count**: {N} tests`
   - Store as: baseline_tests

1. **Compare current tests**:

   - Current test count from Step 2
   - If current_tests < baseline_tests:
     - **REGRESSION DETECTED**: Test count decreased
     - Identify which tests were removed
     - Ask: "Some tests were removed. Continue anyway? (y/n)"
     - If no: Exit with error

1. **Check test results**:

   - If any test FAILED (from CI.py output):
     - **REGRESSION DETECTED**: Tests broken
     - List failing tests
     - Ask: "Some tests are failing. Continue anyway? (y/n)"
     - If no: Exit with error

1. **Regression status**:

   - If no regressions: `âœ… RegressÃ£o = 0`
   - If regressions: `âš ï¸ RegressÃ£o = {count}`

### Step 5: Self-Review Validation

Present interactive checklist:

```
ğŸ“‹ Self-Review Checklist (3 min):

1. CÃ³digo segue padrÃµes do projeto?
   [ ] Naming conventions OK
   [ ] Indentation/formatting OK
   [ ] No code duplication

2. Testes adicionados adequadamente?
   [ ] Tests cover happy path
   [ ] Tests cover edge cases
   [ ] Tests are isolated

3. Componente Ã© isolÃ¡vel?
   [ ] Low coupling to other modules
   [ ] Can be tested in isolation
   [ ] Changes are reversible

4. Sem breaking changes?
   [ ] Existing APIs unchanged
   [ ] Backward compatible
   [ ] No deprecated features removed

Resultado: âœ… APPROVED | âŒ NEEDS REVISION
```

User must answer all 4 questions before proceeding.

### Step 6: Apply Stopping Criteria

Evaluate the 3 decision criteria:

**CritÃ©rio 1**: Success rate >= target?

```
Target (from Section 1): {X}%
Current: {Y}%
Result: {Y >= X ? âœ… PASS : âŒ FAIL}
```

**CritÃ©rio 2**: RegressÃ£o = 0?

```
Regressions detected: {count}
Result: {count == 0 ? âœ… PASS : âŒ FAIL}
```

**CritÃ©rio 3**: Self-review OK?

```
All checklist items: âœ… PASS
Result: âœ… PASS
```

### Step 7: Make Automatic Decision

Based on 3 criteria:

**IF all 3 are PASS**:

```
ğŸ‰ TODOS 3 CRITÃ‰RIOS ATINGIDOS!

Este Ã© o Ãºltimo incremento necessÃ¡rio?
VocÃª pode:
  1. Executar /concluir-slice para finalizar
  2. Criar novo incremento se quiser mais melhorias

Status: Slice pode ser CONCLUÃDA
```

**IF any 1+ is FAIL**:

```
â³ CONTINUAR COM PRÃ“XIMO INCREMENTO

CritÃ©rio(s) nÃ£o atingido(s):
  âŒ Success rate: {Y}% < {X}%
  âŒ RegressÃ£o: {count} testes quebrados
  âŒ Self-review: Item X falhou

PrÃ³ximo passo: /novo-incremento

```

## Update SLICE_TRACKER.md - Incremento N

After all validations complete, update Section 3.N:

### Replace Incremento status:

**OLD**:

```markdown
### Incremento {N}: {Title}

- **Status**: â¡ï¸ Em Progresso
- **Iniciado em**: {ISO_TIMESTAMP}
```

**NEW**:

```markdown
### Incremento {N}: {Title}

- **Status**: âœ… Finalizado
- **Iniciado em**: {ISO_TIMESTAMP}
- **Finalizado em**: {NEW_ISO_TIMESTAMP}
- **DuraÃ§Ã£o Real**: {Xm Ys}
```

### Add Metrics Section:

```markdown
#### MÃ©tricas Finalizadas
- **Success Rate**: {Y}% (delta: +{Y-baseline}%)
- **Test Count**: {N} (delta: +{N-baseline})
- **Coverage**: {Z}%
- **Avg Latency**: {W}ms (delta: {W-baseline}ms)
- **Capturado em**: {ISO_TIMESTAMP}
```

### Add Validations Section:

```markdown
#### ValidaÃ§Ãµes
- âœ… Coverage â‰¥ 70%: {Z}%
- âœ… RegressÃ£o = 0: {count} detected
- âœ… Self-review: [PASSED/FAILED per item]
```

### Add Decision Section:

```markdown
#### DecisÃ£o Final
- **CritÃ©rio 1 (Success Rate)**: {âœ… PASS / âŒ FAIL}
- **CritÃ©rio 2 (RegressÃ£o)**: {âœ… PASS / âŒ FAIL}
- **CritÃ©rio 3 (Self-Review)**: {âœ… PASS / âŒ FAIL}
- **PrÃ³ximo Passo**: {CONTINUAR com /novo-incremento / CONCLUIR com /concluir-slice}
- **RazÃ£o**: {Explanation based on criteria}

#### Commits
- **Base Commit**: {from Section 3.N inicial}
- **Final Commit**: {current HEAD hash}
- **Commit Count**: {number of commits}
```

## Update BACKLOG.md (if exists)

If BACKLOG.md exists, optionally note progress:

1. Find slice in BACKLOG.md
1. Status remains: `â¡ï¸ Em Progresso` (still working)
1. Optionally add note: "N incrementos completed"

## Display Final Report

Show user comprehensive summary:

```
âœ… Incremento {N} Finalizado!

ğŸ“Š MÃ‰TRICAS CAPTURADAS:
   Success Rate: {Y}% (baseline: {X}%, delta: +{Y-X}%)
   Test Count: {N} tests (baseline: {B}, delta: +{N-B})
   Coverage: {Z}% (âœ… >= 70% required)
   Latency: {W}ms
   Timestamp: {ISO_TIMESTAMP}

âœ“ VALIDAÃ‡Ã•ES:
   âœ… Coverage >= 70%: {Z}%
   âœ… RegressÃ£o = 0: {regressÃ£o_count} detected
   âœ… Self-review checklist: ALL PASSED

ğŸ¯ CRITÃ‰RIOS DE PARADA:
   CritÃ©rio 1 (Success Rate): {âœ… PASS / âŒ FAIL}
   CritÃ©rio 2 (RegressÃ£o): {âœ… PASS / âŒ FAIL}
   CritÃ©rio 3 (Self-Review): {âœ… PASS / âŒ FAIL}

â¡ï¸ DECISÃƒO AUTOMÃTICA:

{IF all 3 PASS}:
   ğŸ‰ SLICE PODE SER CONCLUÃDA!

   Todos 3 critÃ©rios atingidos. VocÃª pode:
   1. Executar: /concluir-slice
      â””â”€ Para finalizar e fazer merge
   2. Executar: /novo-incremento
      â””â”€ Para adicionar mais melhorias (opcional)

{IF any FAIL}:
   â³ CONTINUAR COM PRÃ“XIMO INCREMENTO

   CritÃ©rio(s) nÃ£o atingido(s):
   {list failed criteria}

   PrÃ³ximo passo: /novo-incremento

ğŸ“ FILES UPDATED:
   âœ“ docs/slices/SLICE_{N}_TRACKER.md
     â€¢ Section 3.{N} metrics updated
     â€¢ Status: âœ… Finalizado
     â€¢ Decision recorded

ğŸš€ PRÃ“XIMOS PASSOS:
   {IF all pass}:
      1. Review changes: git log --oneline -5
      2. Run /concluir-slice para finalizar
      3. Ou continue com /novo-incremento

   {IF continue}:
      1. Review metrics delta
      2. Run /novo-incremento para prÃ³ximo incremento
      3. Implement suggested activities
```

## Error Handling

**If CI.py fails**:

- Display error output
- Ask: "Fix tests and try again? (y/n)"
- If no: Offer to manually set metrics

**If coverage < 70%**:

- Block with error message
- Suggest areas needing more tests
- Do NOT update incremento status
- User must add tests and re-run

**If regressions detected**:

- Display broken tests
- Ask: "Accept regressions? (y/n)"
- If no: git revert and start over
- If yes: Continue (with warning)

**If self-review fails**:

- Ask user to fix specific items
- Offer to re-run checklist
- Do NOT update incremento status

**If git issues**:

- Verify working directory clean
- Check branch is correct
- Offer to stash changes and continue

## Integration with Other Commands

**Workflow continuation**:

1. `/iniciar-slice` â†’ Section 2 created
1. `/novo-incremento` â†’ Section 3.1 created
1. [Developer codes Incremento 1]
1. `/finalizar-incremento` â† **YOU ARE HERE**
   - Validates all metrics
   - Decides: continue or conclude
1. Loop: goto 2 for Incremento 2, 3, etc
1. After all criteria met: `/concluir-slice` â†’ Section 4 created, merge to main

## Configuration Requirements

### pytest-cov Setup

If not already present, project should have:

**pytest.ini or pyproject.toml**:

```ini
[tool:pytest]
addopts = --cov=. --cov-report=json --cov-report=html
testpaths = tests
```

Or in pyproject.toml:

```toml
[tool.pytest.ini_options]
addopts = "--cov=. --cov-report=json --cov-report=html"
testpaths = ["tests"]
```

### Installation

If pytest-cov not installed:

```bash
uv add pytest-cov --dev
```

## Tips for Best Results

1. **Run frequently**: Don't wait until end to check coverage
1. **TDD approach**: Write tests before code
1. **Check regressions**: Ensure no existing tests break
1. **Review code**: Self-review checklist is important
1. **Keep commits atomic**: 1 increment = 1-3 commits
1. **Update tracker**: Keep Section 3.N up to date
