---
description: Validate USER_STORIES.md against INVEST best practices with 0-100 score and auto-correction plan
allowed-tools: Read, Write, Glob, AskUserQuestion
model: claude-sonnet-4-5
argument-hint: '[USER_STORIES_PATH]'
---

# Validate User Histories

Validate USER_STORIES.md file generated by `/create-user-histories` against INVEST best practices, calculate quality score (0-100), and automatically generate correction plan if score < 90%.

## ğŸ¯ Objective

- Validate each user story against INVEST principles (6 criteria)
- Calculate individual story scores and overall document score (0-100)
- Identify specific quality issues per story (persona, action, benefit, ACs)
- Generate detailed scorecard with breakdown by category
- Auto-generate correction plan if overall score < 90%
- Provide actionable recommendations for each identified issue

## ğŸ”§ Instructions

### 1. Locate and Read USER_STORIES.md

1.1 **Search for USER_STORIES.md**

- If `USER_STORIES_PATH` argument provided: Use that path
- If not provided: Search in standard locations using `Glob`:
  - `docs/USER_STORIES.md`
  - `USER_STORIES.md`
  - `docs/user-stories.md`
  - `*.md` files containing "User Stories" in title
- If multiple found: Ask user which to validate
- If none found: Report error and suggest running `/create-user-histories`

1.2 **Parse USER_STORIES.md Structure**

Extract and validate presence of:

- Document header with agent name
- Stories Overview table (ID, Title, Persona, Priority, Effort)
- Detailed Stories section with full user story format
- Each story must have: persona, action (I want), benefit (So that)
- Acceptance Criteria for each story (Given-When-Then format)
- Traceability Matrix (optional but recommended)

### 2. Validate Each User Story (INVEST Framework)

For EACH story in the document, validate against 6 INVEST criteria:

2.1 **I - Independent (15 points)**

- âœ… 15 pts: No dependencies OR dependencies documented
- âš ï¸ 10 pts: Has undocumented dependencies
- âŒ 0 pts: Circular dependencies or blocked by multiple stories

2.2 **N - Negotiable (10 points)**

- âœ… 10 pts: Flexible implementation, not over-specified
- âš ï¸ 5 pts: Some flexibility
- âŒ 0 pts: Too prescriptive, no room for discussion

2.3 **V - Valuable (20 points)**

**Persona Quality (10 pts):**

- âœ… 10 pts: Specific persona (e.g., "Sales professional", "DevOps engineer")
- âš ï¸ 5 pts: Generic but identifiable (e.g., "Developer")
- âŒ 0 pts: Vague (e.g., "User", "Someone", "Person")

**Benefit Quality (10 pts):**

- âœ… 10 pts: Clear benefit with > 10 characters, explains WHY
- âš ï¸ 5 pts: Benefit present but short (5-10 chars)
- âŒ 0 pts: Vague benefit (e.g., "to work", "to function")

2.4 **E - Estimable (15 points)**

- âœ… 15 pts: Precise estimate (1-6 hours, e.g., "2.5h")
- âš ï¸ 10 pts: Range estimate (e.g., "2-3h")
- âš ï¸ 5 pts: Vague estimate (e.g., "~5h?", "few hours")
- âŒ 0 pts: No estimate OR > 6 hours (too large)

2.5 **S - Small (15 points)**

- âœ… 15 pts: 1-6 hours (ideal 2-3h)
- âš ï¸ 10 pts: 0.5-1h (too small, should group)
- âš ï¸ 5 pts: 6-8h (too large, should split)
- âŒ 0 pts: > 8 hours (way too large)

2.6 **T - Testable (25 points)**

**AC Count (5 pts):**

- âœ… 5 pts: 3-5 ACs
- âš ï¸ 3 pts: 2 ACs
- âŒ 0 pts: < 2 ACs OR > 5 ACs

**AC Specificity (20 pts):**

- âœ… 20 pts: ALL ACs specific and testable (e.g., "success_rate >= 80%", "latency < 2s")
- âš ï¸ 15 pts: Most ACs specific, 1-2 vague
- âš ï¸ 10 pts: Half ACs vague (e.g., "works correctly")
- âŒ 0 pts: Most ACs vague (e.g., "functions", "is ok")

### 3. Calculate Story Scores and Metrics

3.1 **Individual Story Score**

For each story:

```
Story Score = (I + N + V + E + S + T) / 100 * 100
Max: 100 points (15+10+20+15+15+25)
```

3.2 **Calculate Impact/Effort Ratio**

If story has Impact value (1-10 scale):

```
RazÃ£o = Impact / Hours
ğŸ”¥ Excellent: > 3.0
âœ… Good: 1.5-3.0
âš ï¸ Medium: 1.0-1.5
âŒ Poor: < 1.0
```

3.3 **Overall Document Score**

```
Overall Score = (Sum of all story scores) / (Number of stories)
```

### 4. Generate Validation Report

4.1 **Document-Level Scorecard**

Present:

- Overall score: X/100
- Total stories analyzed
- Score distribution: Excellent (>90), Good (75-90), Medium (60-75), Poor (\<60)
- Average Impact/Hours ratio across stories

4.2 **Per-Story Breakdown**

For each story with score < 90:

- Story ID and Title
- Current score: X/100
- INVEST breakdown showing which criteria failed
- Specific issues identified
- Impact/Hours ratio status

4.3 **Category Analysis**

Show aggregate scores by category:

- Persona Quality: X%
- Action Specificity: X%
- Benefit Clarity: X%
- AC Quality: X%
- Size Appropriateness: X%
- Independence: X%

### 5. Auto-Generate Correction Plan (if Overall Score < 90%)

5.1 **Trigger Conditions**

Execute this step ONLY if:

- Overall document score < 90%, OR
- Any story has score < 75 (blocking issue)

5.2 **Correction Plan Structure**

Generate `USER_STORIES_CORRECTION_PLAN.md` with:

```markdown
# Correction Plan: USER_STORIES.md

**Current Score**: X/100
**Target Score**: 90/100
**Stories Needing Correction**: X of Y

---

## ğŸ”´ Critical Issues (Score < 60)

### Story [ID]: [Title] (Score: X/100)

**Issues Identified:**
1. âŒ Vague persona: "[current persona]"
2. âŒ Non-testable ACs: "[AC example]"
3. âš ï¸ Too large: Xh (> 6h)

**Recommended Actions:**
1. Replace persona with specific role (e.g., "API developer")
2. Rewrite AC with measurable criteria (e.g., "response time < 2s")
3. Split into 2 stories of 3h each

**Revised Story Draft:**
[Provide corrected version]

---

## ğŸŸ¡ Medium Issues (Score 60-75)

[Similar format for medium-priority stories]

---

## âœ… Minor Improvements (Score 75-90)

[Quick fixes for near-passing stories]

---

## ğŸ“Š Summary

- Stories to refine: X
- Estimated effort: Xh to implement corrections
- Expected score after fixes: 95/100
```

5.3 **Write Correction Plan**

- Save plan to `docs/USER_STORIES_CORRECTION_PLAN.md`
- If directory doesn't exist: Save to `USER_STORIES_CORRECTION_PLAN.md`

### 6. Report Completion

Display summary:

```text
âœ… Validation completed!
ğŸ“ Analyzed: [path]/USER_STORIES.md
ğŸ“Š Overall Score: X/100 [ğŸŸ¢|ğŸŸ¡|ğŸ”´]
ğŸ“ˆ Stories: X total, Y excellent (>90), Z need improvement (<75)
ğŸ¯ Average RazÃ£o: X.X

[If score < 90]
ğŸ“ Correction plan generated: docs/USER_STORIES_CORRECTION_PLAN.md
ğŸ”§ Next step: Review plan and refine stories
```

## ğŸ“Š Output Format

### Validation Report Structure

```markdown
# ğŸ“‹ USER_STORIES.md Validation Report

**Document**: [path]
**Overall Score**: X/100 ğŸŸ¢
**Validation Date**: [YYYY-MM-DD]

---

## ğŸ“Š Executive Summary

| Metric | Value | Status |
|--------|-------|--------|
| Total Stories | X | - |
| Average Score | X/100 | ğŸŸ¢ |
| Excellent (>90) | X stories | - |
| Good (75-90) | X stories | - |
| Needs Work (<75) | X stories | - |
| Avg Impact/Hours | X.X | ğŸ”¥ |

**Status Legend:**
- ğŸŸ¢ Excellent: â‰¥90%
- ğŸŸ¡ Good: 75-89%
- ğŸ”´ Needs Improvement: <75%

---

## ğŸ“ˆ Detailed Story Analysis

### ğŸŸ¢ Story US-001: [Title] (Score: 95/100)

**INVEST Breakdown:**
- âœ… Independent: 15/15
- âœ… Negotiable: 10/10
- âœ… Valuable: 20/20 (Persona: âœ…, Benefit: âœ…)
- âœ… Estimable: 15/15
- âœ… Small: 15/15
- âœ… Testable: 20/25 (1 AC slightly vague)

**Impact/Hours Ratio**: 8 / 2.5 = 3.2 ğŸ”¥ EXCELLENT

**Minor Issue:**
- AC3: "Works correctly" â†’ Suggest: "Returns HTTP 200 with valid JSON structure"

---

### ğŸ”´ Story US-003: [Title] (Score: 55/100) âš ï¸

**INVEST Breakdown:**
- âš ï¸ Independent: 10/15 (undocumented dependency)
- âœ… Negotiable: 10/10
- âŒ Valuable: 5/20 (Persona: vague "user", Benefit: âŒ "to work")
- âŒ Estimable: 5/15 (vague "~10h?")
- âŒ Small: 0/15 (10h > 6h limit)
- âŒ Testable: 5/25 (Most ACs vague)

**Impact/Hours Ratio**: 5 / 10 = 0.5 âŒ POOR (consider discarding)

**Critical Issues:**
1. âŒ Persona too vague: "user" â†’ Needs specific role
2. âŒ Benefit unclear: "to work" (4 chars) â†’ Needs clear WHY (>10 chars)
3. âŒ Too large: 10h â†’ Split into 2-3 stories
4. âŒ Vague ACs: "works", "is ok" â†’ Need measurable criteria

**Action Required:** REFINE COMPLETELY before adding to backlog

---

## ğŸ¯ Category Scorecard

| Category | Avg Score | Status | Top Issue |
|----------|-----------|--------|-----------|
| Persona Quality | 85% | ğŸŸ¡ | 3 stories use "user" |
| Action Specificity | 92% | ğŸŸ¢ | Good overall |
| Benefit Clarity | 78% | ğŸŸ¡ | 4 benefits < 10 chars |
| AC Quality | 68% | ğŸ”´ | Many vague ACs |
| Size (1-6h) | 88% | ğŸŸ¡ | 2 stories > 6h |
| Independence | 95% | ğŸŸ¢ | Good overall |

---

## ğŸ”§ Recommendations

**High Priority (Fix Now):**
1. Refine US-003, US-007 (scores < 60)
2. Make all ACs measurable (add numbers, thresholds)
3. Split oversized stories (> 6h)

**Medium Priority:**
1. Specify vague personas (replace "user" with roles)
2. Expand short benefits (< 10 chars)

**Low Priority:**
1. Document dependencies for US-004

---

## âœ… Next Steps

[If score >= 90]
âœ… Stories are ready for backlog!
ğŸ¯ Proceed to `/backlog` or `/spike-agentic`

[If score < 90]
âš ï¸ Correction plan generated: USER_STORIES_CORRECTION_PLAN.md
ğŸ”§ Review and apply corrections
ğŸ”„ Re-run `/validate-user-histories` after fixes
```

## âœ… Success Criteria

- [ ] USER_STORIES.md file located and read successfully
- [ ] All stories parsed correctly (persona, action, benefit, ACs extracted)
- [ ] Each story validated against 6 INVEST criteria
- [ ] Individual story scores calculated (0-100 scale)
- [ ] Impact/Hours ratio calculated for each story (if Impact available)
- [ ] Overall document score calculated
- [ ] Detailed validation report generated
- [ ] Per-story breakdown with specific issues identified
- [ ] Category scorecard showing aggregate metrics
- [ ] If score < 90%: Correction plan auto-generated
- [ ] Correction plan includes revised story drafts
- [ ] Summary report displayed to user
- [ ] Next steps clearly communicated

## ğŸ“ Examples

### Example 1: Validate default location

**Command:**

```bash
/validate-user-histories
```

**Process:**

1. Searches for `docs/USER_STORIES.md`
1. Finds file with 7 user stories
1. Validates each against INVEST
1. Calculates scores: 5 excellent (>90), 2 need work (\<75)
1. Overall score: 82/100 ğŸŸ¡
1. Generates correction plan for 2 low-scoring stories
1. Reports: "82/100 - Good, minor improvements needed"

### Example 2: Validate custom path

**Command:**

```bash
/validate-user-histories projects/email-agent/USER_STORIES.md
```

**Process:**

1. Reads specified file
1. Finds 5 stories, all well-formed
1. All stories score >90
1. Overall score: 94/100 ğŸŸ¢
1. No correction plan needed
1. Reports: "94/100 - Excellent! Ready for backlog"

### Example 3: Poor quality stories (auto-correction triggered)

**Command:**

```bash
/validate-user-histories
```

**Process:**

1. Reads `docs/USER_STORIES.md`
1. Finds 10 stories with mixed quality
1. Identifies issues:
   - 4 stories have vague personas ("user", "person")
   - 6 stories have non-testable ACs ("works", "is ok")
   - 2 stories too large (>6h)
1. Overall score: 67/100 ğŸ”´
1. Auto-generates `USER_STORIES_CORRECTION_PLAN.md` with:
   - Specific persona suggestions for 4 stories
   - Rewritten ACs with measurable criteria for 6 stories
   - Split recommendations for 2 oversized stories
1. Reports: "67/100 - Needs improvement. Correction plan ready."

## âŒ Anti-Patterns

### âŒ Error 1: Accepting Vague Personas

Don't pass stories with generic personas:

```markdown
# âŒ Wrong - Accept as valid
**As a** user
Score: 90/100 âœ…

# âœ… Correct - Flag and penalize
**As a** user
Persona Quality: 0/10 âŒ
Suggestion: Use specific role like "Sales professional" or "DevOps engineer"
```

### âŒ Error 2: Not Validating AC Testability

Don't skip validation of acceptance criteria specificity:

```markdown
# âŒ Wrong - Accept vague ACs
"Works correctly" âœ…
"Functions well" âœ…

# âœ… Correct - Require measurable criteria
"Works correctly" âŒ â†’ "Returns HTTP 200 with valid JSON in < 2s"
"Functions well" âŒ â†’ "Success rate >= 90% on 100 test samples"
```

### âŒ Error 3: Ignoring Story Size

Don't accept stories that are too large or too small:

```markdown
# âŒ Wrong
Story with 12h estimate: Score 80/100 (ignores size issue)

# âœ… Correct
Story with 12h estimate: Score 40/100
Size: 0/15 âŒ
Action: Split into 2-3 stories of 3-4h each
```

### âŒ Error 4: Not Calculating Impact/Hours Ratio

Don't skip ratio analysis when Impact data available:

```markdown
# âŒ Wrong - Skip ratio calculation
Story: Impact=3, Hours=8
Score: 75/100 (based only on INVEST)

# âœ… Correct - Include ratio analysis
Story: Impact=3, Hours=8
INVEST Score: 75/100
RazÃ£o: 3/8 = 0.375 âŒ POOR (< 1.0)
Recommendation: Reconsider value vs effort, may not be worth implementing
```

### âŒ Error 5: Generic Correction Plans

Don't provide vague suggestions in correction plan:

```markdown
# âŒ Wrong - Vague plan
"Improve persona"
"Make ACs better"
"Fix story size"

# âœ… Correct - Specific actionable plan
**Current**: "As a user, I want the system to work better"
**Issue**: Vague persona ("user"), vague action ("work better")
**Corrected**: "As a DevOps engineer, I want automated health checks every 30s so that I detect failures within 1 minute"
**Changes**:
- Persona: "user" â†’ "DevOps engineer"
- Action: "work better" â†’ "automated health checks every 30s"
- Benefit: Added clear WHY ("detect failures within 1 minute")
```

### âŒ Error 6: Not Triggering Auto-Correction

Don't skip correction plan generation when score < 90%:

```markdown
# âŒ Wrong
Overall Score: 85/100
Report ends, no correction plan

# âœ… Correct
Overall Score: 85/100 ğŸŸ¡
âš ï¸ Below 90% threshold - generating correction plan...
âœ… Correction plan saved: USER_STORIES_CORRECTION_PLAN.md
Next step: Review and apply corrections
```
